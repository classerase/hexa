// The Hexa Compiler
// Copyright (C) 2018  Oleg Petrenko
// Copyright (C) 2018  Bogdan Danylchenko
//
// This library is free software; you can redistribute it and/or
// modify it under the terms of the GNU Lesser General Public
// License as published by the Free Software Foundation; either
// version 2.1 of the License, or (at your option) any later version.
//
// This library is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
// Lesser General Public License for more details.
//
// You should have received a copy of the GNU Lesser General Public
// License along with this library; if not, write to the Free Software
// Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA

module {
class Parser {
	new(lexe: Tokens) {
		lex = lexe

		var el = []
		while (i < lex.length && tok() != Token.Eof) {
			el.push(parseExpr())
		}

		node = el[0]
		if (el.length == 0) node = null
		if (el.length > 1) node = Node.TBlock(el)

	// TODO fix trailing atts
		//if (atts.length > 0) {
		//	Process.stdout.write('\n')
		// 	throw fail("Not all attributes conceived")
		// }
	}

	function parseFields() {
		var fields = []
		while (tok() != Token.BrClose) {
			var atts: Array < { name: String, values: Array<Node> } > = []
			while (tok() == Token.At) {
				atts.push(parseAttribute())
			}

			var _static = false
			if (tok() == Token.KStatic) {
				_static = true
				i++
			}

			switch (tok()) {
			case Token.KPrivate:
				i++
			case KVar, KFunction, KLet:
				var f = parseExpr()
				if (_static) f = Node.TStatic(f)
				Project.mapAttributes.set(f, atts)
				fields.push(f)
			case Token.KNew:
				i++
				var expr = null
				var vars = []
				var types = []
				var values = []
				step(Token.POpen)
				while (tok() != Token.PClose) {
					vars.push(getgo(Token.LLower))
					if (tok() == Token.DblDot) {
						i++
						types.push(parseType())
					}
					if (tok() == Token.OpAssign) {
						i++
						values.push(parseExpr())
					}
					if (tok() == Token.Comma) i++
				}
				step(Token.PClose)
				// TODO Attributes parsing breaks this
				var tmp = i
				while (tok() == Token.At) parseAttribute()
				if (tok() != Token.BrClose && tok() != Token.KFunction /*&& tok() != KStatic*/)
				{
					i = tmp
					expr = parseExpr()
				} else i = tmp

				var v = []
				for (i in vars.length) {
					v.push(Node.TVar(vars[i], types[i], values[i], true))
				}
				fields.push(Node.TFunction('new', expr, v, null))
			case _:
				throw fail('Field cannot start with ' + print())
			}
		}
		return fields
	}

	//------------------
	//       DATA
	//------------------

	// Lexemes input directly from lexer
	var node: Node
	private var lex: Tokens
	// The pointer
	private var i = 0
	private var lasttok = -1
	private var lasttokchecks = 10

	//------------------
	//     HELPERS
	//------------------

	static var uuid = 0
	static function uid() return uuid++

	// Current token
	function tok() {
		if (i > lex.length) {
			Console.log("Parser is out of token space!")
			Console.log("This should NOT happen.")
			Console.log("Please, issue a developer (with a sample code).")
			throw fail(lex.fileName + ": Parser Internal Error: Out of token space")
		}
		var t = lex.token[i]
		if (lasttok != i) {
			//Process.stdout.write(lex.token[i].stringify(lex.value[i]))
			lasttok = i
			lasttokchecks = 40
		} else {
			lasttokchecks--
			if (lasttokchecks < 0) {
				throw fail("Parser Internal Error: Same token parsed too many times: " + '`\(print())`')
			}
		}
		return t
	}

	function print() return Token.stringify(lex.token[i], lex.value[i])

	function expect(t) if (t != tok()) expected(Token.stringify(t))

	function fail(message: String, ?line, ?column, ?filename) {
		let line = line != null ? line : lex.line[i]
		let column = column != null ? column : lex.column[i]
		let filename = filename != null ? filename : lex.fileName
		return new CompilerError(Fail.ParserError, message, line, column, filename)
	}

	// function node(nd: Node) {
	// 	Project.data.set(nd, new NodeData(lex.line[i], lex.column[i], lex.fileName))
	// }

	function getgo(t): String {
		expect(t)
		return lex.value[i++]
	}

	function step(t): Void {
		expect(t)
		i++
	}

	@inline function next(): Void {
		i++
	}

	@inline function offset(v): Token {
		return lex.token[i+v]
	}

	//------------
	//   ERRORS
	//------------

	function unexpected() {
		var token = Token.stringify(lex.token[i], lex.value[i])
		if (tok() == Token.Semicolon) Console.log('Note, that Hexa has no semicolons!')
		if (print() == 'public') Console.log('Note, that Hexa has no `public` keyword!')
		throw fail('Unexpected `\(token)`')
	}

	function expected(str: String) {
		var token = Token.stringify(lex.token[i], lex.value[i])
		throw fail('Expected `\(str)` before `\(token)`')
	}

	//-----------------
	//   EXPRESSIONS
	//-----------------

	var class_external = false
	function parseExpr(): Node {
		var atts: Array < { name: String, values: Array<Node> } > = []
		while (tok() == Token.At) atts.push(parseAttribute())
		var node = tok()
		//-------------
		// PREFIX STEP
		//-------------
		var nodePosition = { line: lex.line[i], column: lex.column[i] }
		var result: Node =
		switch (node) {
		case Token.KUsing:
			//
			// TODO Namespaces with dots
			//
			next()
			var names = [getgo(Token.LUpper)]

			while (tok() == Token.Comma) {
				step(Token.Comma)
				names.push(getgo(Token.LUpper))
				// names.push(getgo(LLower))
			}
			TUsing(names)

		// if (tok() == BrOpen)
		// 	fail('Incorrect `declare` syntax! Use `declare function name(): T`')

		// declare class C {}
		case KDeclare if (lex.token[i + 1] == KClass):
			i++
			var c = parseExpr()
			switch (c) {
				case TClass(t, ext, impl, fields, _): TClass(t, ext, impl, fields, true)
				case _: throw "Error KDeclare TClass"
			}

		case KDeclare:
			i++
			var e = switch (tok()) {
				case KFunction: parseFunction(false)
				case LUpper:
					var left = parseType()
					step(OpAssign)
					TBinop(NodeTypeValue(left), OpAssign, NodeTypeValue(parseType()))
				case _:
					parseExpr()
			}

			var name: String = null
			var extracted = null
			switch (e) {
				case Node.TPrivate(el):
				extracted = el
				case Node.TStatic(el):
				extracted = el
				case Node.TExport(el):
				extracted = el
				case _: extracted = e
			}

			switch (extracted) {
				case TBinop(NodeTypeValue(Type(n)), OpAssign, _): name = n
				case TBinop(NodeTypeValue(ParametricType(n, _)), OpAssign, _): name = n
				case TBinop(TIdent(n), OpAssign, _): name = n

				case TClass(Type(n), _): name = n
				case TClass(ParametricType(n, _), _): name = n
				case TVar(n, t, e, _):
					switch [t, e] {
						case [null, _]:
							throw fail('Variable `\(n)` in `declare` should have a type')
						case [_,null]:
							name = n // Correct
						case _:
							throw fail('Variable `\(n)` in `declare` should *not* have a value')
					}
				case TFunction(n, e, _, _):
					switch [n, e] {
						case [null, _]:
							throw fail('Function in `declare` should have a name')
						case [_, null]:
							name = n // Correct
						case _:
							throw fail('Functions in `declare` should *not* have a body')
					}
				// TODO binop assign
				// Types-to-types `T = T` or idents-to-idents `name = name` should be assigned
				// TODO require type for var and func args / retT?
				case Node.TVars(_):
					throw fail('Place only one variable into `declare`')
				case _:
					throw fail('Incorrect `declare` syntax! Use `declare let name: T` or `declare function name(): T`')
			}
			// Having name is ok here, coz we search by name in scopes
			TDeclare(name, e)

			//switch (tok()) {
			//	case LUpper:
			//		var name = getgo(LUpper)
			//		step(OpAssign)
			//		TDeclare(name, parseExpr())
			//	// case LLower:
			//	// 	var name = getgo(LLower)
			//	// 	step(OpAssign)
			//	// 	TDeclare(name, parseExpr())
			//	case KClass:
			//	class_external = true
			//	var f = parseExpr()
			//	class_external = false
			//	f
			//	case KFunction:
			//	var name = lex.value[i+1]
			//	TDeclare(name, parseExpr())
			//	case KVar, KLet:
			// 	var name = lex.value[i+1]
			// 	if (name == null) throw new CompilerError(Fail.ParserError, 'TDeclare name null')
			// //	TDeclare(name, parseExpr())

			// 	case _: // ParseDeclareError?
			// 		throw new CompilerError(Fail.ParserError, "declare expects name or type")
			//}

		// []
		case Token.BrOpen:
			i++
			if (tok() == Token.BrClose) { // Empty block
				i++
				TBlock([])
			} else if (tok() == Token.DblDot) { // Empty object
				i++
				TObject([], [])
				step(Token.BrClose)
			} else if (tok() == Token.LLower && lex.token[i + 1] == Token.DblDot) { // Object
				var names: Array<String> = [], el: Array<Node> = []
				while (tok() != Token.BrClose) {
					names.push(getgo(Token.LLower))
					step(Token.DblDot)
					el.push(parseExpr())
					if (tok() == Token.Comma) i++
				}
				TObject(names, el)
				step(Token.BrClose)
			} else { // Block
				var el = []
				while (tok() != Token.BrClose) {
					el.push(parseExpr())
				}
				TBlock(el)
				step(Token.BrClose)
			}
		case Token.KIf:
			i++
			step(Token.POpen)
			var econd = [parseExpr()]
			while (tok() == Token.Comma) {
				next()
				econd.push(parseExpr())
			}
			step(Token.PClose)
			var eif = null
			if (tok() != Token.DblDot) {
				eif = parseExpr()
			}
			var eelse: Null<Node> = null
			if (tok() == Token.KElse) {
				i++
				eelse = parseExpr()
			}
			TIf(econd, eif, eelse)
		// while () {}
		case Token.KWhile:
			i++
			step(Token.POpen)
			var econd = parseExpr()
			step(Token.PClose)
			var e = parseExpr()
			TWhile(econd, e, true)
		// do {} while ()
		case Token.KDo:
			i++
			var e = parseExpr()
			step(Token.KWhile)
			step(Token.POpen)
			var econd = parseExpr()
			TWhile(econd, e, false)
			step(Token.PClose)
		case Token.POpen:
			next()
			if (
				// () =>
				(tok() == Token.PClose && offset(1) == Token.OpArrow) ||
				// (a, ...) =>
				(tok() == Token.LLower && offset(1) == Token.Comma) ||
				// (a: ...) =>
				(tok() == Token.LLower && offset(1) == Token.DblDot) ||
				// (a) =>
				(tok() == Token.LLower && offset(1) == Token.PClose && offset(2) == Token.OpArrow)
			) {
				var vars = []
				var types = []
				var values = []
				while (tok() != Token.PClose) {
					vars.push(getgo(Token.LLower))
					if (tok() == Token.DblDot) {
						i++
						types.push(parseType())
					}
					if (tok() == Token.OpAssign) {
						i++
						values.push(parseExpr())
					}
					if (tok() == Token.Comma) i++
				}
				step(Token.PClose)
				step(Token.OpArrow)
				var v = []
				for (i in vars.length) {
					v.push(Node.TVar(vars[i], types[i], values[i], true))
				}
				TFunction(null, parseExpr(), v, null)
			} else {
				var expr = parseExpr()
				TParenthesis(expr)
				step(Token.PClose)
			}
		// return e
		// return
		case Token.KReturn: i++
			switch (tok()) {
				case BrClose, KVar: TReturn(null)
				case _: TReturn(parseExpr())
			}
		case KThrow: i++; TThrow(parseExpr())
		case KContinue: i++; TContinue
		case KBreak: i++; TBreak
		case Underscore: i++; TUnderscore
		case OpNegBits: i++; TUnop(OpNegBits, false, parseExpr())
		case OpSub: i++; TUnop(OpSub, false, parseExpr())
		case OpNot: i++; TUnop(OpNot, false, parseExpr())
		case OpIncrement: i++; TUnop(OpIncrement, false, parseExpr())
		case OpDecrement: i++; TUnop(OpDecrement, false, parseExpr())
		case Interval: i++; TUnop(Interval, false, parseExpr())
		case LFloat: TFloat(getgo(LFloat))
		case LInt: TInt(getgo(LInt))
		case LUpper:
			if (lex.token[i+1] == OpLt) {
				var res = parseType()
				NodeTypeValue(res)
			} else {
				TIdent(name)
				var name = getgo(Token.LUpper)
			}
		case Token.LLower:
			var name = getgo(Token.LLower)
			if (tok() == Token.OpArrow) {
				next()
				TFunction(null, parseExpr(), [TVar(name, null, null, true)], null)
			} else TIdent(name)
		case Token.LString:
			var str = getgo(Token.LString)
			// TODO Check have interpolations in string
			if (hasInterpolation(str))
				TParenthesis(parseInterpolations(str))
			else TString(str)
		case KTrue:  i++; TBool(true)
		case KFalse: i++; TBool(false)
		case KThis: i++; TThis
		case KNull:  i++; TNull
		case KSuper:  i++; TSuper
		case KVar, KLet:
			var parsed = parseVar()
			(parsed.length > 1) ? TVars(parsed) : parsed[0]
		case Token.KTry:
			i++
			var expr = parseExpr()
			var vars = []
			var t = []
			var v = []
			var catches = []
			while (tok() == Token.KCatch) {
				step(Token.KCatch)
				step(Token.POpen)
				var name = getgo(Token.LLower)
				vars.push(name)
				step(Token.DblDot)
				var type = parseType()
				{
					t.push(type)
				}
				v.push(Node.TVar(name, type, null, true))
				step(Token.PClose)
				catches.push(parseExpr())
			}
			TTry(expr, t, v, catches)

		case Token.KModule:
			i++
			var path = []
			// TODO Corrent by upperlower mode
			if (tok() == Token.LLower) {
				path.push(getgo(Token.LLower))
				while (tok() == Token.Dot) {
					i++
					path.push(getgo(Token.LLower))
				}
			}
			step(Token.BrOpen)
			var el = []
			while (tok() != Token.BrClose) {
				el.push(parseExpr())
			}
			TModule(path, el)
			step(Token.BrClose)

		case Token.KEnum:
			i++
			var t = parseType()
			if (tok() == Token.DblDot) {
				i++
				parseType()
			}
			step(Token.BrOpen)
			var names = []
			while (tok() != Token.BrClose) {
				while (tok() == Token.At) atts.push(parseAttribute())
				atts = []
				names.push(parseExpr())
			}
			TEnum(t, names)
			step(Token.BrClose)

		case Token.KClass | Token.KInterface:
			var isInterface = tok() == Token.KInterface
			var att = atts
			atts = []
			i++
			var t = parseType()

			var ext = if (tok() == Token.KExtends) {
				i++
				parseType()
			} else null

			var impl = []
			while (tok() == Token.KImplements) {
				i++
				impl.push(parseType())
			}

			step(Token.BrOpen)
			var fields = parseFields()
			step(Token.BrClose)
			var me = Node.TClass(t, ext, impl, fields, class_external)
			//Project.mapAttributes.set(me, atts)
			Project.mapAttributes.set(me, att)
			me
			parseFunction()
		case Token.KFunction:
		case Token.BkOpen:
			i++
			var el = []
			var values = []
			var isMap = false

			while (tok() != Token.BkClose) {
				if (tok() == Token.DblDot) {
					isMap = true
					next()
					break
				}
				el.push(parseExpr())
				if (tok() == Token.DblDot) {
					i++
					values.push(parseExpr())
					isMap = true
				}
				if (tok() == Token.Comma) i++
			}
			step(Token.BkClose)

			if (isMap)
				TMap(el, values)
			else TArray(el)
		case Token.KNew:
			i++
			var t = parseType()
			var names: Array<String> = []
			var values: Array<Node> = []
			if (tok() == Token.BrOpen) {
				i++
				if (tok() == Token.DblDot) { // Empty object
					i++
					step(Token.BrClose)
				} else if (tok() == Token.LLower && lex.token[i + 1] == Token.DblDot) { // Object
					while (tok() != Token.BrClose) {
						names.push(getgo(Token.LLower))
						step(Token.DblDot)
						values.push(parseExpr())
						if (tok() == Token.Comma) i++
					}
					step(Token.BrClose)
				}
				else if (tok() == Token.BrClose) {
					step(Token.BrClose)
				}
			}
			step(Token.POpen)
			var args = []
			while (tok() != Token.PClose) {
				args.push(parseExpr())
				if (tok() == Token.Comma) i++
			}
			step(Token.PClose)

			TNew([], t, args, names, values)
		case Token.KSwitch:
			i++
			step(Token.POpen)
			var exprs = []
			while (tok() != Token.PClose) {
				exprs.push(parseExpr())
				if (tok() == Token.Comma) i++
			}
			step(Token.PClose)
			step(Token.BrOpen)

			var cases = []
			var conds = []

			while (tok() != Token.BrClose) {
				step(Token.KCase)
				var cond = []
				while (tok() != Token.DblDot) {
					if (tok() == Token.Underscore) {
						i++
						cond.push(Node.TUnderscore)
					} else cond.push(parseExpr())
					if (tok() == Token.Comma) i++
				}
				conds.push(cond)
				step(Token.DblDot)
				var exs = []
				while (tok()!=Token.KCase && tok()!=Token.BrClose) {
					exs.push(parseExpr())
				}
				cases.push(Node.TBlock(exs))
			}

			TSwitch(exprs, conds, cases)
			step(Token.BrClose)

		case Token.KFor:
			i++
			step(Token.POpen)
			var n = getgo(Token.LLower)
			step(Token.KIn)
			var a = parseExpr()
			step(Token.PClose)
			var b = parseExpr()
			TFor(n, a, b)

		case Token.KStatic:
			next()
			TStatic(parseExpr())
		case Token.KPrivate:
			next()
			TPrivate(parseExpr())

		// case LComment:
		// 	next()
		// 	// var arr: Array<Node> = new Array()
		// 	// arr.push(TString(getgo(LComment)))
		// 	// atts.push({
		// 	// 	name: "comment",
		// 	// 	values: arr })
		// 	null
		// case LCommentLine:
		// 	next()
		// null

		case _: unexpected() null
		}
		if (result == null) {
			Process.stdout.write('\n')
			throw fail("Expression is incomplete, current tokens is: " + Token.stringify(tok()))
		}
		Project.data.set(result, new NodeData(nodePosition.line, nodePosition.column, lex.fileName)) // map element at prefix step

		if (atts.length > 0) {
			Project.mapAttributes.set(result, atts)
			atts = []
		}

		//--------------
		// POSTFIX STEP
		//--------------
		var done = false
		while (!done) {
			result = switch (tok()) {
			case Token.BkOpen:
				i++
				var index = parseExpr()
				TIndex(result, index)
				step(Token.BkClose)
			case Token.KIs:
				i++
				switch (tok()) {
						TIs(result, parseType())
					case Token.LUpper:
					case _:
						throw fail("Cannot parse type `" + Token.stringify(tok()) + "`")
				}
			case Token.KAs:
				i++
				var kind = tok()
				TAs(result, kind, parseType())
				if (tok() == Token.OpNot) i++
				else if (tok() == Token.Question) i++
				else kind = Token.Default
			case Token.POpen: { // call
				var args: Array<Node> = []
				var argNames: Array<String> = []
				i++
				while (tok() != Token.PClose) {
					var argname = null
					switch (tok()) {
						case Token.LUpper:
							args.push(parseExpr())
							if (tok() == Token.DblDot) {
								step(Token.DblDot)
								parseType()
							}
						case _:
							if (lex.token[i+1] == Token.DblDot) {
								argNames.push(getgo(Token.LLower))
								step(Token.DblDot)
							}
							else {
								argNames.push(null)
							}
							args.push(parseExpr())
					}
					if (tok() != Token.PClose) step(Token.Comma)
				}
				TCall(result, args, argNames)
				step(Token.PClose)
			}
			case Token.OpArrow:
				next()
				TFunction(null, parseExpr(), [result], null)

			case OpIncrement: i++; TUnop(OpIncrement, true, result)
			case OpDecrement: i++; TUnop(OpDecrement, true, result)
			case Dot: i++
				var name = switch (tok()) { // TODO Refact
					case LUpper: getgo(LUpper)
					case _: getgo(LLower)
				}
				TDot(result, name)

			// a ? b : c
			// a ?? b
			// a ?. b
					TDot(result, name)
			case Token.Question: i++
				if (tok() == Token.Dot) {
					var name = getgo(Token.LLower)
				} else if (tok() == Token.Question) {
					i++
					TElvis(result, parseExpr())
				} else {
					var eif = parseExpr()
					step(Token.DblDot)
					var eelse = parseExpr()
					TIf([result], eif, eelse)
				}
				parseExpr()
			case Token.OpChain: i++
			// a += b
			case t if (isBinop(t) && offset(1) == OpAssign):
				var op = tok()
				i++
				i++
				var b = parseExpr()
				TAssignop(result, op, b)
			// a + b
			case t if (isBinop(t)):
				i++
				//if (tok() == OpAssign) { // +=
				//	i++
				//}
				var b = parseExpr()
				var a = result
				switch (b) {
				case Node.TBinop(aa, op, bb):
					var tp = precedence(t)
					var tLeft = tp > 99
					tp = tp % 100
					var bp = precedence(op)
					var bLeft = bp > 99
					bp = bp % 100
					if (bp > tp)
						TBinop(TBinop(result, t, aa), op, bb)
					else
						TBinop(result, t, b)

				case _: TBinop(result, t, b)
				}
			case _: done = true result
			}
		}
		if (result == null) {
			Process.stdout.write('\n')
			throw fail("Expression postfix is incomplete")
		}

		if (atts.length > 0) {
			Project.mapAttributes.set(result, atts)
			atts = []
		}
		Project.data.set(result, new NodeData(nodePosition.line, nodePosition.column, lex.fileName))
		return result
	}

	function parseVar(): Array<Node> {

		// let data.Node.TIdent(s1) = node

		var const = tok() == Token.KLet
		i++
		var vars: Array<Node> = []

		function parseSingleVar(): Node {
			var varname = getgo(Token.LLower)
			if (varname.endsWith("___")) throw fail("Variables can't end with `___`, it is reserved.")
			var type = null if (tok() == Token.DblDot) { i++ type = parseType() }
			var expr = null if (tok() == Token.OpAssign) { i++ expr = parseExpr() }
			return Node.TVar(varname, type, expr, const)
		}

		function parseSingleBinding(): Node {
			var path = []
			// Path let path.path.path.
			while (tok() == Token.LLower && offset(1) == Token.Dot) {
				path.push(getgo(Token.LLower))
				i++
			}
			// Enum type
			path.push(getgo(Token.LUpper))
			step(Token.Dot)
			// Enum exact tag
			path.push(getgo(Token.LUpper))

			// Enum bind vars or none
			if (tok() == Token.POpen && offset(1) == Token.PClose) throw fail("Don't use empty parenthesis for `let " + path.join('.') + '()` bindings')
			var bind = [] // Variables T(var, var, var)
			if (tok() == Token.POpen) {
				do {
					i++
					if (tok() == Token.Underscore) { i++ bind.push(null) }
					else bind.push(Node.TVar(getgo(Token.LLower), null, null, const))
				} while (tok() == Token.Comma)
				step(Token.PClose)
			}

			step(Token.OpAssign)

			var expr = parseExpr()
			return Node.TEnumExtract(path, bind, expr)
			//throw fail("parseSingleBinding " + path + ' ' + bind + ' ' + expr)
		}

		while (true) {

			if (tok() == Token.LUpper || (tok() == Token.LLower && offset(1) == Token.Dot))
				vars.push(parseSingleBinding())
			else vars.push(parseSingleVar())

			// Multiple variables var a, b, c
			if (tok() == Token.Comma && offset(1) == Token.LLower && (offset(2) == Token.OpAssign || offset(2) == Token.DblDot))
				i++
			else break
		}

		return vars

		var const = tok() == Token.KLet
		i++
		var vars: Array<Node> = []
		switch (tok()) {
			// var a
			case Token.LLower:
				// TODO Refactor
				while (true) {

					var varname = getgo(Token.LLower)
					if (varname.endsWith("___")) throw fail("Variables can't end with `___`, it is reserved.")

					var type = null if (tok() == Token.DblDot) { i++ type = parseType() }
					var expr = null if (tok() == Token.OpAssign) { i++ expr = parseExpr() }
					vars.push(Node.TVar(varname, type, expr, const))

					if (tok() == Token.Comma && offset(1) == Token.LLower && (offset(2) == Token.OpAssign || offset(2) == Token.DblDot))
						i++
					else break
				}
			// var Left
			case Token.LUpper:
				// if (offset(1) != Dot) {
				// 	throw fail("Please use lowercase for variable")
				// }
				// // var Left.B
				// else {
					var left = Node.TIdent(getgo(Token.LUpper))
					var res = left
					// var Left.B.C.D...
					while (tok() == Token.Dot) {
						res = Node.TDot(res, getgo(Token.LUpper))
					}
					switch (tok()) {
						case Token.POpen:
							var args: Array<String> = []
							while (tok() != Token.PClose) {
								args.push(getgo(Token.LLower))
							}
							step(Token.OpAssign)
							var varname = getgo(Token.LLower)
							//!vars.push(TEnumExtract(res, args, varname))
						case Token.OpAssign:
							//warning Extracting empty enum
						case _:
							throw fail("Wrong syntax")
					}
				// }
			case _:
				throw fail("Wrong syntax")
		}
		return vars
	}

	function parseFunction(?parseBody): Node {
		parseBody = parseBody != null ? parseBody : true
		i++
		var expr = null
		var name = null
		var vars = []
		var types = []
		var values = []
		switch (tok()) {
			case Token.LLower:
				name = getgo(Token.LLower)
			case Token.LUpper: throw fail("Function names can't start with uppercase.")
			case _:
		}
		step(Token.POpen)
		{
			while (tok() != Token.PClose) {
				var expr = null
				var t = null
				if (tok() == Token.Interval) {
					i++
				}
				var name = getgo(Token.LLower)
				if (tok() == Token.DblDot) {
					i++
					t = parseType()
				}
				if (tok() == Token.OpAssign) {
					i++
					expr = parseExpr()
				}
				vars.push(name)
				types.push(t)
				values.push(expr)
				if (tok() == Token.Comma) i++
			}
			step(Token.PClose)
		}
		var rettype = null
		if (tok() == Token.DblDot) {
			i++
			rettype = parseType()
		}

		if (parseBody) switch (tok()) {
			case KNew if (lex.token[i+1] == POpen): {}
			case BrClose, KStatic, KPrivate, KFunction: {}
			case Token.At: {
				var tmp = i
				while (tok() == Token.At) parseAttribute()
				if (tok() != Token.BrClose && tok() != Token.KStatic && tok() != Token.KPrivate && tok() != Token.KFunction)
				{
					i = tmp
					expr = parseExpr()
				} else i = tmp
			}
			case _: expr = parseExpr()
		}

		var v = []
		for (i in vars.length) {
			v.push(Node.TVar(vars[i], types[i], values[i], true))
		}
		return (Node.TFunction(name, expr, v, rettype))
	}

	function hasInterpolation(str: String): Bool {
		var chars = str.split("")
		var i = 0
		while (i < chars.length) {
			if (chars[i] == "\\")
				if (i+1 < chars.length)
					if (chars[i+1] == "\\")
						i++
					else if (chars[i+1] == "(")
						return true
			i++
		}
		return false
	}

	function parseInterpolations(str: String): Node {
		var chars = str.split("")
		var resStr = "\""
		var i = 0
		var inScopes = false
		var scopes = ""
		var scopeCount = 0
		while (i < chars.length) {
			var char = chars[i]
			switch (char) {
				case "\"":
					resStr += "\\\""
					i++
					continue
				case "\\":
					if (i+1 < chars.length)
						if (chars[i+1] == "\\") {
							i++
							char += "\\"
						}
						else if (chars[i+1] == "(") {
							inScopes = true
							resStr += "\" + ("
							i += 2
							continue
						}
				case "(":
					if (inScopes)
						scopeCount++
				case ")":
					if (scopeCount > 0) {
						scopeCount--
					}
					else {
						resStr += scopes + ") + \""
						inScopes = false
						scopes = ""
						i++ continue
					}
				case _:
			}
			if (inScopes) scopes += char
			else { resStr += char }
			i++
		}
		resStr += "\""
		var tokens = Lexer.tokenize(Buffer.from(resStr), "")
		try {
			var parsed = new Parser(tokens)
			switch (parsed.node) {
				case TParenthesis(TBlock(_)), TBlock(_): throw null
				case _: return parsed.node
			}
		}
		catch(e: Any) {
			throw fail("Parse interpolation error: " + e)
		}
	}

	function parseAttribute() {
		i++
		var name = getgo(Token.LLower)
		var values = []
		if (tok() == Token.POpen) {
			i++
			while (tok() != Token.PClose) {
				values.push(parseExpr())
				if (tok() == Token.Comma) i++
			}
			step(Token.PClose)
		}
		return { name: name, values: values }
	}

	var parametricTypeNesting = 0
	var parametricTypeNestingToken = Token.Eof
	function parseType(): NodeType {
		var path = []
		while (tok() == Token.LLower && offset(1) == Token.Dot) {
			path.push(getgo(Token.LLower))
			i++
		}

		var result =
		switch (tok()) {
		case Token.LUpper:
			var name = getgo(Token.LUpper)
			if (path.length != 0) name = path.join('.') + '.' + name
			while (tok() == Token.Dot) {
				i++
				getgo(Token.LUpper)
			}
			var result = if (tok() == OpLt) {
				i++
				parametricTypeNesting++
				var params: Array<NodeType> = [parseType()]
				while (tok() == Token.Comma) {
					i++
					params.push(parseType())
				}

				if (parametricTypeNestingToken == Token.Eof) parametricTypeNestingToken = tok()

				switch (parametricTypeNestingToken) {
					case Token.OpGt: parametricTypeNesting-=1 parametricTypeNestingToken = Token.Eof i++
					case Token.OpShr: parametricTypeNesting-=1 parametricTypeNestingToken = Token.OpGt
					case Token.OpUShr: parametricTypeNesting-=1 parametricTypeNestingToken = Token.OpUShr
					case _: unexpected()
				}
				if (parametricTypeNesting < 0)
					throw fail("parametricTypeNesting < 0")

				ParametricType(name, params)
			} else Type(name)

			// A => B
			if (tok() == Token.OpArrow) {
				i++
				result = Function([result], parseType())
			}

			result
		case BkOpen if (path.length == 0): // [Type]
			i++
			var res: NodeType = null
			res = switch (tok()) {
				case Token.BkClose:
					i++
					ParametricType("Array", [Object([], [])])
				case Token.DblDot:
					i++
					if (tok() == Token.BkClose) {
						i++
						ParametricType("Map", [Object([], []), Object([], [])])
					}
					else {
						ParametricType("Map", [Object([], []), parseType()])
					}
				case _:
					var key = parseType()
					var innerRes = if (tok() == Token.DblDot) { // Map
						i++
						ParametricType("Map", [key, parseType()])
					} else ParametricType("Array", [key])
					step(Token.BkClose)
					if (tok() == Token.OpArrow) {
						i++
						innerRes = NodeType.Function([res], parseType())
					}
					innerRes
			}
			res
		case BrOpen if (path.length == 0): // {}
			i++
			var result = if (tok() == DblDot) { // Empty
				i++
				Object([], [])
			} else {
				var names: Array<String> = []
				var types: Array<NodeType> = []
				while (tok() != Token.BrClose) {
					names.push(getgo(Token.LLower))
					if (tok() == Token.DblDot) {
						i++
						types.push(parseType())
					}
					if (tok() == Token.Comma) i++
				}
				Object(names, types)
			}
			step(Token.BrClose)
			if (tok() == Token.OpArrow) {
				i++
				result = Function([result], parseType())
			}
			result
		case POpen if (path.length == 0): // ()
			i++
			var args = []
			while (tok() != Token.PClose) {
				parseType()
				if (tok() == Token.DblDot) {
					i++
					args.push(parseType())
				}
				if (tok() == Token.Comma) i++
			}
			Function(args, parseType())
			step(Token.PClose)
			step(Token.OpArrow)
		// var.invar
		// var.Invar
		//
			var res: NodeType = switch (offset(1)) {
		case Token.LLower:
				case Token.DblDot: {
					var argName = getgo(tok())
					step(Token.DblDot)
					var argType = parseType()
					FunctionArg(argName, argType, null)
				}
				//case Dot: {
				//	i += 2
				//	parseType()
				//}
				case _: {
					throw fail("Typename can not start with lowercase")
				}
			}
			res

		case _:
			throw fail("Expected Type, parsed `" + Token.stringify(tok()) + "`")
		}

		if (tok() == Token.Question) {
			result = NodeType.Optional(result)
		}
		while (tok() == Token.Question) i++
		if (tok() == Token.OpArrow) {
			i++
			result = NodeType.Function([result], parseType())
		}
		return result
	}

	function precedence(op: Token) {
		var left = 100
		var right = 0
		return switch (op) {
			case OpMod: 0 + left
			case OpMult | OpDiv: 1 + left
			case OpAdd | OpSub: 2 + left
			case OpShl | OpShr | OpUShr: 3 + left
			case OpOr | OpAnd | OpXor: 4 + left
			case OpEq | OpNotEq | OpGt | OpLt | OpGte | OpLte: 5 + left
			case OpBoolAnd: 7 + left
			case OpBoolOr: 8 + left
			case OpAssign: 10 + right
			case _: // TODO proper message, this is internal error
				throw fail("No precedence for " + Token.stringify(op))
		}
	}

	static function isBinop(t: Token): Bool {
		return switch (t) {
		case	OpAdd,
				OpMult,
				OpDiv,
				OpSub,
				OpAssign,
				OpEq,
				OpNotEq,
				OpGt,
				OpGte,
				OpLt,
				OpLte,
				OpAnd,
				OpOr,
				OpXor,
				OpBoolAnd,
				OpBoolOr,
				OpShl,
				OpShr,
				OpUShr,
				OpMod
				: true
		case _: false
		}
	}
}
}
